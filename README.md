# NTUAI2024

## Task 1

### modelcard
* [Blip](https://huggingface.co/Salesforce/blip-image-captioning-base)
* [Phi-4](https://huggingface.co/microsoft/Phi-4-multimodal-instruct)

### dataset
* [mscoco](https://huggingface.co/datasets/nlphuji/mscoco_2014_5k_test_image_text_retrieval)
* [flickr30k](https://huggingface.co/datasets/nlphuji/flickr30k)

## Task 2

### modelcard
* **_MLLM Model:_** [Phi-4](https://huggingface.co/microsoft/Phi-4-multimodal-instruct)
* **_T2I Model:_** [Stable Diffusion 3](https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers)
* **_I2I Model:_** [Stable Diffusion v1-5](https://huggingface.co/stable-diffusion-v1-5/stable-diffusion-v1-5)

### dataset
* [CeleFace](https://drive.google.com/file/d/1VU3yMVG_MyDUTBkRIZxmIu1-tUkHzuJT/view)

### Restriction
* Output Image Format: $224 \times 224$
* No additional model or fine tuning
